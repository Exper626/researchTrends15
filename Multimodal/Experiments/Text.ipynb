{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekYz_wCddd-6"
   },
   "outputs": [],
   "source": [
    "!unzip text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bON7G7sQeREN"
   },
   "outputs": [],
   "source": [
    "# ================================ FINAL WORKING VERSION – 2199 ALIGNED SEGMENTS ================================\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# ================================ DATA LOADER (FIXED WITH INTERVAL ALIGNMENT) ================================\n",
    "def load_mosi_text_only(\n",
    "    text_path='text/CMU_MOSI_TimestampedWordVectors_1.1.csd',\n",
    "    label_path='text/CMU_MOSI_Opinion_Labels.csd'\n",
    "):\n",
    "    print(f\"Loading text from: {text_path}\")\n",
    "    text_data = {}  # video_id -> {'features': (W, 300), 'intervals': (W, 2)}\n",
    "\n",
    "    with h5py.File(text_path, 'r') as f:\n",
    "        root = f['glove_vectors']['data']\n",
    "        for video_id in root.keys():\n",
    "            group = root[video_id]\n",
    "            if 'features' in group and 'intervals' in group:\n",
    "                features = group['features'][()].astype(np.float32)\n",
    "                intervals = group['intervals'][()].astype(np.float32)\n",
    "                text_data[video_id] = {'features': features, 'intervals': intervals}\n",
    "            else:\n",
    "                print(f\"Warning: Video {video_id} missing features or intervals. Skipping.\")\n",
    "\n",
    "    print(f\"→ Loaded text for {len(text_data)} videos\")\n",
    "\n",
    "    # Load labels and segment intervals\n",
    "    print(f\"Loading labels from: {label_path}\")\n",
    "    label_data = {}  # video_id -> {'labels': (S,), 'intervals': (S, 2)}\n",
    "\n",
    "    with h5py.File(label_path, 'r') as f:\n",
    "        root = f['Opinion Segment Labels']['data']\n",
    "        for video_id in root.keys():\n",
    "            group = root[video_id]\n",
    "            if 'features' not in group or 'intervals' not in group:\n",
    "                print(f\"Warning: Video {video_id} missing label features or intervals. Skipping.\")\n",
    "                continue\n",
    "            raw_labels = group['features'][()]\n",
    "            intervals = group['intervals'][()].astype(np.float32)\n",
    "\n",
    "            if raw_labels.ndim > 1 and raw_labels.shape[-1] == 7:\n",
    "                # Probability distribution to expected value\n",
    "                scores = np.dot(raw_labels, np.arange(-3, 4)).astype(np.float32)\n",
    "            else:\n",
    "                scores = raw_labels.flatten().astype(np.float32)\n",
    "\n",
    "            label_data[video_id] = {'labels': scores, 'intervals': intervals}\n",
    "\n",
    "    print(f\"→ Loaded labels for {len(label_data)} videos\")\n",
    "    total_labels = sum(len(v['labels']) for v in label_data.values())\n",
    "    print(f\"→ Total label segments: {total_labels}\")\n",
    "\n",
    "    # Align: For each segment, extract matching word features using intervals\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for video_id in sorted(text_data.keys()):\n",
    "        if video_id not in label_data:\n",
    "            print(f\"SKIP: {video_id} has text but no labels\")\n",
    "            continue\n",
    "\n",
    "        text_feats = text_data[video_id]['features']\n",
    "        text_ints = text_data[video_id]['intervals']\n",
    "        seg_labels = label_data[video_id]['labels']\n",
    "        seg_ints = label_data[video_id]['intervals']\n",
    "\n",
    "        if len(seg_labels) != len(seg_ints):\n",
    "            print(f\"Error: Mismatch in {video_id} label count vs intervals. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        for i in range(len(seg_labels)):\n",
    "            seg_start, seg_end = seg_ints[i]\n",
    "\n",
    "            # Find words where word_start >= seg_start and word_end <= seg_end\n",
    "            # Assuming intervals are sorted by start time\n",
    "            start_idx = np.searchsorted(text_ints[:, 0], seg_start, side='left')\n",
    "            end_idx = np.searchsorted(text_ints[:, 1], seg_end, side='right')\n",
    "\n",
    "            seg_feat = text_feats[start_idx:end_idx]\n",
    "            if len(seg_feat) == 0:\n",
    "                seg_feat = np.zeros((1, 300), dtype=np.float32)\n",
    "            else:\n",
    "                # Trim any all-zero rows (unlikely for GloVe, but safe)\n",
    "                nonzero = np.where(np.any(seg_feat != 0, axis=1))[0]\n",
    "                if len(nonzero) > 0:\n",
    "                    seg_feat = seg_feat[:nonzero[-1] + 1]\n",
    "\n",
    "            sequences.append(seg_feat)\n",
    "            labels.append(seg_labels[i])\n",
    "\n",
    "    assert len(sequences) == len(labels), f\"Final mismatch: {len(sequences)} seqs vs {len(labels)} labels\"\n",
    "    print(f\"\\nSUCCESS! Aligned {len(sequences)} segments\")\n",
    "    print(f\"Label range: {min(labels):.2f} to {max(labels):.2f}\")\n",
    "    print(f\"Average segment length: {np.mean([len(s) for s in sequences]):.1f} words\")\n",
    "\n",
    "    return sequences, np.array(labels, dtype=np.float32)\n",
    "\n",
    "\n",
    "# ================================ DATASET & COLLATE ================================\n",
    "class MOSIDataset(Dataset):\n",
    "    def __init__(self, seqs, labs, max_len=50):\n",
    "        self.seqs = seqs\n",
    "        self.labs = labs\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = self.seqs[i]\n",
    "        if len(x) > self.max_len:\n",
    "            x = x[:self.max_len]\n",
    "        if len(x) < self.max_len:\n",
    "            pad = np.zeros((self.max_len - len(x), 300), dtype=np.float32)\n",
    "            x = np.concatenate([x, pad], axis=0)\n",
    "        return torch.from_numpy(x), torch.tensor(self.labs[i], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    seqs, labs = zip(*batch)\n",
    "    seqs = torch.stack(seqs)\n",
    "    labs = torch.stack(labs).unsqueeze(1)\n",
    "    lengths = torch.tensor([min(len(orig_seq), 50) for orig_seq in [s for s, _ in batch]])\n",
    "    return seqs, labs, lengths\n",
    "\n",
    "\n",
    "# ================================ MODEL (BiLSTM + Attention) ================================\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(300, 256, num_layers=2, bidirectional=True, batch_first=True, dropout=0.5)\n",
    "        self.attn = nn.Linear(512, 1)\n",
    "        self.norm = nn.LayerNorm(512)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(0.5), nn.Linear(512, 128), nn.GELU(),\n",
    "            nn.Dropout(0.3), nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lens):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        a = self.attn(out).squeeze(-1)\n",
    "        a = a.masked_fill(torch.arange(x.size(1), device=x.device)[None, :] >= lens[:, None], -1e9)\n",
    "        a = torch.softmax(a, dim=1)\n",
    "        ctx = (out * a.unsqueeze(-1)).sum(1)\n",
    "        ctx = self.norm(ctx)\n",
    "        return self.head(ctx)\n",
    "\n",
    "\n",
    "# ================================ TRAIN LOOP ================================\n",
    "def train():\n",
    "    print(\"Loading CMU-MOSI text data...\")\n",
    "    seqs, labs = load_mosi_text_only()\n",
    "\n",
    "    # Stratified split (binary: positive vs negative/neutral)\n",
    "    bin_lab = (labs >= 0).astype(int)\n",
    "    tr_x, val_x, tr_y, val_y = train_test_split(\n",
    "        seqs, labs, test_size=0.2, random_state=42, stratify=bin_lab\n",
    "    )\n",
    "\n",
    "    tr_ds = MOSIDataset(tr_x, tr_y, max_len=50)\n",
    "    val_ds = MOSIDataset(val_x, val_y, max_len=50)\n",
    "\n",
    "    tr_dl = DataLoader(tr_ds, batch_size=32, shuffle=True, collate_fn=collate, num_workers=2, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = Model().to(device)\n",
    "    opt = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    sch = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=7)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    max_patience = 20\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING STARTED\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        for x, y, l in tr_dl:\n",
    "            x, y, l = x.to(device), y.to(device), l.to(device)\n",
    "            opt.zero_grad()\n",
    "            p = model(x, l)\n",
    "            loss = loss_fn(p, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y, l in val_dl:\n",
    "                x, y, l = x.to(device), y.to(device), l.to(device)\n",
    "                p = model(x, l)\n",
    "                val_loss += loss_fn(p, y).item()\n",
    "\n",
    "        tr_loss /= len(tr_dl)\n",
    "        val_loss /= len(val_dl)\n",
    "        sch.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Train MSE: {tr_loss:.4f} | Val MSE: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-4:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_mosi_text_final.pth\")\n",
    "            print(f\"   >>> BEST MODEL! Val MSE = {best_val_loss:.4f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nFINISHED! Best Validation MSE = {best_val_loss:.4f}\")\n",
    "    print(\"Model saved as: best_mosi_text_final.pth\")\n",
    "\n",
    "\n",
    "# ================================ RUN ================================\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
