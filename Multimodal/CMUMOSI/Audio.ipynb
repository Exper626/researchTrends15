{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iSNCb7Pi1Ea",
    "outputId": "fdf93702-48fc-4c27-bb87-1e58be1aa9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  audio.zip\n",
      "   creating: audio/\n",
      "  inflating: audio/CMU_MOSI_COVAREP.csd  \n",
      "  inflating: audio/CMU_MOSI_Opinion_Labels.csd  \n"
     ]
    }
   ],
   "source": [
    "!unzip audio.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8_91gSHyo-T",
    "outputId": "41dac1b7-2fbc-4cdc-9b2a-f5506df76770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla T4\n",
      "Audio top-level keys: ['COVAREP']\n",
      "Generated 14384 audio chunks\n",
      "Label top-level keys: ['Opinion Segment Labels']\n",
      "Final dataset: 14384 samples, labels [-3.00, 3.00]\n",
      "----------------------------------------------------------------------\n",
      "Start training: 11507 train / 2877 val chunks\n",
      "\n",
      "Epoch 01 | Train 2.7958 | Val 2.7693 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.7693\n",
      "Epoch 02 | Train 2.6462 | Val 2.5405 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.5405\n",
      "Epoch 03 | Train 2.5310 | Val 2.5553 | LR 3.00e-04\n",
      "Epoch 04 | Train 2.4144 | Val 2.3911 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.3911\n",
      "Epoch 05 | Train 2.3077 | Val 2.3107 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.3107\n",
      "Epoch 06 | Train 2.2449 | Val 2.2078 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.2078\n",
      "Epoch 07 | Train 2.1609 | Val 2.0869 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.0869\n",
      "Epoch 08 | Train 2.0828 | Val 2.0279 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.0279\n",
      "Epoch 09 | Train 2.0236 | Val 2.0083 | LR 3.00e-04\n",
      "  → New best! Val MSE = 2.0083\n",
      "Epoch 10 | Train 1.9942 | Val 1.9992 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.9992\n",
      "Epoch 11 | Train 1.9646 | Val 1.8397 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.8397\n",
      "Epoch 12 | Train 1.8587 | Val 1.8777 | LR 3.00e-04\n",
      "Epoch 13 | Train 1.9629 | Val 2.1649 | LR 3.00e-04\n",
      "Epoch 14 | Train 1.8425 | Val 1.6936 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.6936\n",
      "Epoch 15 | Train 1.8061 | Val 1.7307 | LR 3.00e-04\n",
      "Epoch 16 | Train 1.7858 | Val 1.6280 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.6280\n",
      "Epoch 17 | Train 1.7735 | Val 1.6931 | LR 3.00e-04\n",
      "Epoch 18 | Train 1.6556 | Val 1.5400 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.5400\n",
      "Epoch 19 | Train 1.6716 | Val 1.5796 | LR 3.00e-04\n",
      "Epoch 20 | Train 1.6411 | Val 1.5832 | LR 3.00e-04\n",
      "Epoch 21 | Train 1.6218 | Val 1.4871 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.4871\n",
      "Epoch 22 | Train 1.5523 | Val 2.1514 | LR 3.00e-04\n",
      "Epoch 23 | Train 1.5865 | Val 1.6472 | LR 3.00e-04\n",
      "Epoch 24 | Train 1.5876 | Val 1.7075 | LR 3.00e-04\n",
      "Epoch 25 | Train 1.5526 | Val 1.4780 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.4780\n",
      "Epoch 26 | Train 1.5457 | Val 1.3953 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.3953\n",
      "Epoch 27 | Train 1.6062 | Val 1.4797 | LR 3.00e-04\n",
      "Epoch 28 | Train 1.4763 | Val 1.9548 | LR 3.00e-04\n",
      "Epoch 29 | Train 1.4249 | Val 1.4875 | LR 3.00e-04\n",
      "Epoch 30 | Train 1.4731 | Val 1.3676 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.3676\n",
      "Epoch 31 | Train 1.4402 | Val 1.4359 | LR 3.00e-04\n",
      "Epoch 32 | Train 1.3593 | Val 1.3173 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.3173\n",
      "Epoch 33 | Train 1.4708 | Val 1.3165 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.3165\n",
      "Epoch 34 | Train 1.3613 | Val 1.2774 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.2774\n",
      "Epoch 35 | Train 1.3819 | Val 1.2347 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.2347\n",
      "Epoch 36 | Train 1.4084 | Val 1.2413 | LR 3.00e-04\n",
      "Epoch 37 | Train 1.3799 | Val 1.2496 | LR 3.00e-04\n",
      "Epoch 38 | Train 1.4097 | Val 1.2960 | LR 3.00e-04\n",
      "Epoch 39 | Train 1.3562 | Val 1.4986 | LR 3.00e-04\n",
      "Epoch 40 | Train 1.3800 | Val 1.1980 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.1980\n",
      "Epoch 41 | Train 1.2965 | Val 1.2382 | LR 3.00e-04\n",
      "Epoch 42 | Train 1.3256 | Val 1.4533 | LR 3.00e-04\n",
      "Epoch 43 | Train 1.3585 | Val 1.3421 | LR 3.00e-04\n",
      "Epoch 44 | Train 1.3553 | Val 1.1454 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.1454\n",
      "Epoch 45 | Train 1.2916 | Val 1.1968 | LR 3.00e-04\n",
      "Epoch 46 | Train 1.3346 | Val 1.4238 | LR 3.00e-04\n",
      "Epoch 47 | Train 1.3023 | Val 1.1133 | LR 3.00e-04\n",
      "  → New best! Val MSE = 1.1133\n",
      "Epoch 48 | Train 1.3397 | Val 1.1865 | LR 3.00e-04\n",
      "Epoch 49 | Train 1.2761 | Val 1.3883 | LR 3.00e-04\n",
      "Epoch 50 | Train 1.2757 | Val 1.1248 | LR 3.00e-04\n",
      "Epoch 51 | Train 1.3480 | Val 1.1906 | LR 3.00e-04\n",
      "Epoch 52 | Train 1.2494 | Val 1.2174 | LR 3.00e-04\n",
      "Epoch 53 | Train 1.2595 | Val 1.1693 | LR 1.50e-04\n",
      "Epoch 54 | Train 1.1115 | Val 1.0065 | LR 1.50e-04\n",
      "  → New best! Val MSE = 1.0065\n",
      "Epoch 55 | Train 1.1075 | Val 1.1413 | LR 1.50e-04\n",
      "Epoch 56 | Train 1.1104 | Val 1.1623 | LR 1.50e-04\n",
      "Epoch 57 | Train 1.1009 | Val 1.1027 | LR 1.50e-04\n",
      "Epoch 58 | Train 1.0805 | Val 1.0292 | LR 1.50e-04\n",
      "Epoch 59 | Train 1.1245 | Val 0.9960 | LR 1.50e-04\n",
      "  → New best! Val MSE = 0.9960\n",
      "Epoch 60 | Train 1.0499 | Val 0.9917 | LR 1.50e-04\n",
      "  → New best! Val MSE = 0.9917\n",
      "Epoch 61 | Train 1.1210 | Val 1.0281 | LR 1.50e-04\n",
      "Epoch 62 | Train 1.0299 | Val 1.0406 | LR 1.50e-04\n",
      "Epoch 63 | Train 1.0759 | Val 1.1629 | LR 1.50e-04\n",
      "Epoch 64 | Train 1.0627 | Val 0.9991 | LR 1.50e-04\n",
      "Epoch 65 | Train 1.0407 | Val 1.0515 | LR 1.50e-04\n",
      "Epoch 66 | Train 1.0553 | Val 1.1872 | LR 7.50e-05\n",
      "Epoch 67 | Train 1.0040 | Val 1.0141 | LR 7.50e-05\n",
      "Epoch 68 | Train 0.9453 | Val 0.9159 | LR 7.50e-05\n",
      "  → New best! Val MSE = 0.9159\n",
      "Epoch 69 | Train 0.9438 | Val 0.9159 | LR 7.50e-05\n",
      "Epoch 70 | Train 0.9536 | Val 0.9073 | LR 7.50e-05\n",
      "  → New best! Val MSE = 0.9073\n",
      "Epoch 71 | Train 0.9395 | Val 0.9335 | LR 7.50e-05\n",
      "Epoch 72 | Train 0.9401 | Val 1.0032 | LR 7.50e-05\n",
      "Epoch 73 | Train 0.9409 | Val 0.9384 | LR 7.50e-05\n",
      "Epoch 74 | Train 0.9470 | Val 0.9796 | LR 7.50e-05\n",
      "Epoch 75 | Train 0.9483 | Val 1.0214 | LR 7.50e-05\n",
      "Epoch 76 | Train 0.9204 | Val 0.9446 | LR 3.75e-05\n",
      "Epoch 77 | Train 0.8853 | Val 0.9234 | LR 3.75e-05\n",
      "Epoch 78 | Train 0.8777 | Val 0.9121 | LR 3.75e-05\n",
      "Epoch 79 | Train 0.8690 | Val 0.9058 | LR 3.75e-05\n",
      "  → New best! Val MSE = 0.9058\n",
      "Epoch 80 | Train 0.8763 | Val 0.9089 | LR 3.75e-05\n",
      "Epoch 81 | Train 0.8728 | Val 0.8780 | LR 3.75e-05\n",
      "  → New best! Val MSE = 0.8780\n",
      "Epoch 82 | Train 0.8612 | Val 0.9457 | LR 3.75e-05\n",
      "Epoch 83 | Train 0.8706 | Val 0.8856 | LR 3.75e-05\n",
      "Epoch 84 | Train 0.8584 | Val 0.8723 | LR 3.75e-05\n",
      "  → New best! Val MSE = 0.8723\n",
      "Epoch 85 | Train 0.8513 | Val 0.8998 | LR 3.75e-05\n",
      "Epoch 86 | Train 0.8674 | Val 0.8832 | LR 3.75e-05\n",
      "Epoch 87 | Train 0.8535 | Val 0.9051 | LR 3.75e-05\n",
      "Epoch 88 | Train 0.8525 | Val 0.8883 | LR 3.75e-05\n",
      "Epoch 89 | Train 0.8570 | Val 0.8953 | LR 3.75e-05\n",
      "Epoch 90 | Train 0.8634 | Val 0.8693 | LR 3.75e-05\n",
      "  → New best! Val MSE = 0.8693\n",
      "Epoch 91 | Train 0.8430 | Val 0.8890 | LR 3.75e-05\n",
      "Epoch 92 | Train 0.8534 | Val 0.8703 | LR 3.75e-05\n",
      "Epoch 93 | Train 0.8546 | Val 0.8691 | LR 3.75e-05\n",
      "  → New best! Val MSE = 0.8691\n",
      "Epoch 94 | Train 0.8618 | Val 0.8827 | LR 3.75e-05\n",
      "Epoch 95 | Train 0.8546 | Val 0.8870 | LR 3.75e-05\n",
      "Epoch 96 | Train 0.8560 | Val 0.8821 | LR 3.75e-05\n",
      "Epoch 97 | Train 0.8583 | Val 0.8698 | LR 3.75e-05\n",
      "Epoch 98 | Train 0.8339 | Val 0.9027 | LR 3.75e-05\n",
      "Epoch 99 | Train 0.8325 | Val 0.9006 | LR 1.87e-05\n",
      "Epoch 100 | Train 0.8237 | Val 0.8534 | LR 1.87e-05\n",
      "  → New best! Val MSE = 0.8534\n",
      "\n",
      "Training finished! Best Val MSE: 0.8534\n",
      "Model saved as 'best_mosi_audio_chunked.pth'\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================= GPU SETUP =============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# =========================== DATA LOADER (Works with real MOSI files) ===========================\n",
    "def load_and_chunk_mosi(audio_path, label_path, chunk_len=200, stride=100):\n",
    "    # --- Load audio (COVAREP) ---\n",
    "    with h5py.File(audio_path, 'r') as f:\n",
    "        print(\"Audio top-level keys:\", list(f.keys()))\n",
    "        if 'COVAREP' in f:\n",
    "            data_group = f['COVAREP']['data']\n",
    "        else:\n",
    "            data_group = f['data']                  # newer format\n",
    "        segment_ids = sorted(data_group.keys())\n",
    "\n",
    "        chunks = []\n",
    "        seg_lengths = {}\n",
    "\n",
    "        for seg_id in segment_ids:\n",
    "            feats = data_group[seg_id]['features'][:]\n",
    "            feats = np.nan_to_num(feats, nan=0.0).astype(np.float32)\n",
    "            L = len(feats)\n",
    "            seg_lengths[seg_id] = L\n",
    "            for i in range(0, max(1, L - chunk_len + 1), stride):\n",
    "                chunks.append(feats[i:i+chunk_len])\n",
    "\n",
    "    print(f\"Generated {len(chunks)} audio chunks\")\n",
    "\n",
    "    # --- Load labels ---\n",
    "    with h5py.File(label_path, 'r') as f:\n",
    "        print(\"Label top-level keys:\", list(f.keys()))\n",
    "        if 'Opinion Segment Labels' in f:\n",
    "            label_group = f['Opinion Segment Labels']['data']\n",
    "        else:\n",
    "            label_group = f['data']\n",
    "\n",
    "        labels = []\n",
    "        chunk_idx = 0\n",
    "        for seg_id in segment_ids:\n",
    "            if seg_id not in label_group:\n",
    "                # skip chunks belonging to missing segment\n",
    "                n_chunks = max(1, (seg_lengths[seg_id] - chunk_len + stride) // stride)\n",
    "                chunk_idx += n_chunks\n",
    "                continue\n",
    "\n",
    "            raw = label_group[seg_id]['features'][:]\n",
    "            if raw.shape[-1] == 7:  # one-hot\n",
    "                label = float(np.dot(raw.flatten(), np.arange(-3, 4)))\n",
    "            else:\n",
    "                label = float(raw.flatten()[0])\n",
    "\n",
    "            n_chunks = max(1, (seg_lengths[seg_id] - chunk_len + stride) // stride)\n",
    "            labels.extend([label] * n_chunks)\n",
    "            chunk_idx += n_chunks\n",
    "\n",
    "    # Trim any extra chunks (safety)\n",
    "    chunks = chunks[:len(labels)]\n",
    "    assert len(chunks) == len(labels), f\"{len(chunks)} != {len(labels)}\"\n",
    "\n",
    "    print(f\"Final dataset: {len(chunks)} samples, labels [{min(labels):.2f}, {max(labels):.2f}]\")\n",
    "    print(\"-\" * 70)\n",
    "    return chunks, labels\n",
    "\n",
    "\n",
    "# =========================== DATASET ===========================\n",
    "class MOSIChunkDataset(Dataset):\n",
    "    def __init__(self, chunks, labels):\n",
    "        self.chunks = chunks\n",
    "        self.labels = labels\n",
    "    def __len__(self): return len(self.chunks)\n",
    "    def __getitem__(self, i):\n",
    "        return torch.from_numpy(self.chunks[i]), torch.tensor(self.labels[i], dtype=torch.float32)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, labs = zip(*batch)\n",
    "    lengths = torch.tensor([s.shape[0] for s in seqs])\n",
    "    max_len = lengths.max()\n",
    "    padded = torch.zeros(len(seqs), max_len, 74, dtype=torch.float32)\n",
    "    for i, s in enumerate(seqs):\n",
    "        padded[i, :lengths[i]] = s\n",
    "    labels = torch.stack(labs).unsqueeze(1)\n",
    "    return padded, labels, lengths\n",
    "\n",
    "\n",
    "# =========================== MODEL ===========================\n",
    "class AudioSentimentLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(74, 128, num_layers=2, batch_first=True,\n",
    "                            bidirectional=True, dropout=0.4)\n",
    "        self.norm = nn.LayerNorm(256)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x, lengths):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        h = torch.cat((hn[-2], hn[-1]), dim=1)   # (B, 256)\n",
    "        h = self.norm(h)\n",
    "        return self.head(h)\n",
    "\n",
    "\n",
    "# =========================== TRAINING ===========================\n",
    "def train():\n",
    "    chunks, labels = load_and_chunk_mosi(\n",
    "        'audio/CMU_MOSI_COVAREP.csd',        # or .h5\n",
    "        'audio/CMU_MOSI_Opinion_Labels.csd'  # or .h5\n",
    "    )\n",
    "\n",
    "    train_c, val_c, train_y, val_y = train_test_split(\n",
    "        chunks, labels, test_size=0.2, random_state=42,\n",
    "        stratify=[int(l > 0) for l in labels]   # rough balance\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(MOSIChunkDataset(train_c, train_y), batch_size=64,\n",
    "                              shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(MOSIChunkDataset(val_c, val_y), batch_size=64,\n",
    "                              shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = AudioSentimentLSTM().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val = float('inf')\n",
    "    patience = 15\n",
    "    no_improve = 0\n",
    "\n",
    "    print(f\"Start training: {len(train_c)} train / {len(val_c)} val chunks\\n\")\n",
    "\n",
    "    for epoch in range(1, 101):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x, y, lengths in train_loader:\n",
    "            x, y, lengths = x.to(device), y.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x, lengths)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y, lengths in val_loader:\n",
    "                x, y, lengths = x.to(device), y.to(device), lengths.to(device)\n",
    "                pred = model(x, lengths)\n",
    "                val_loss += criterion(pred, y).item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss   /= len(val_loader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | Train {train_loss:.4f} | Val {val_loss:.4f} | LR {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save(model.state_dict(), \"best_mosi_audio_chunked.pth\")\n",
    "            print(f\"  → New best! Val MSE = {best_val:.4f}\")\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nTraining finished! Best Val MSE: {best_val:.4f}\")\n",
    "    print(\"Model saved as 'best_mosi_audio_chunked.pth'\")\n",
    "\n",
    "\n",
    "# =========================== RUN ===========================\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
