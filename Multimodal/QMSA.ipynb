{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef051d-61cd-4eb3-b574-3ce8f7da3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qmsa_pytorch.py\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# -------------------------\n",
    "# Utilities: embeddings\n",
    "# -------------------------\n",
    "def load_glove_embeddings(glove_path, dims=100):\n",
    "    \"\"\"\n",
    "    Load GloVe txt file into a dict[word] -> numpy vector.\n",
    "    \"\"\"\n",
    "    emb = {}\n",
    "    with open(glove_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vals = np.array(parts[1:], dtype=np.float32)\n",
    "            if vals.shape[0] != dims:\n",
    "                continue\n",
    "            emb[word] = vals\n",
    "    return emb\n",
    "\n",
    "def normalize_vec(v):\n",
    "    v = v.astype(np.float64)\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0:\n",
    "        return v\n",
    "    return (v / norm).astype(np.float32)\n",
    "\n",
    "# -------------------------\n",
    "# Build projectors\n",
    "# -------------------------\n",
    "def word_projectors_from_text(text_tokens, emb_map, dim):\n",
    "    \"\"\"\n",
    "    text_tokens: list of tokens\n",
    "    emb_map: dict token->vector\n",
    "    returns: list of projectors (numpy arrays dim x dim)\n",
    "    \"\"\"\n",
    "    P = []\n",
    "    for t in text_tokens:\n",
    "        if t not in emb_map:\n",
    "            continue\n",
    "        w = normalize_vec(emb_map[t])\n",
    "        # rank-1 projector: outer product\n",
    "        Pi = np.outer(w, w)  # shape (dim, dim)\n",
    "        P.append(Pi.astype(np.float32))\n",
    "    return P\n",
    "\n",
    "def build_visual_vocab(image_paths, k=128, sample_limit=None):\n",
    "    \"\"\"\n",
    "    Extract SIFT descriptors for images and run kmeans to get visual words.\n",
    "    Returns k cluster centers (k x 128)\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    descs = []\n",
    "    for i, p in enumerate(tqdm(image_paths, desc=\"SIFT features\")):\n",
    "        if sample_limit and i >= sample_limit:\n",
    "            break\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        kp, d = sift.detectAndCompute(img, None)\n",
    "        if d is not None:\n",
    "            descs.append(d)\n",
    "    if len(descs) == 0:\n",
    "        raise RuntimeError(\"No SIFT descriptors found.\")\n",
    "    descs = np.vstack(descs)\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=4096, verbose=0, random_state=42)\n",
    "    km.fit(descs)\n",
    "    centers = km.cluster_centers_\n",
    "    # normalize centers\n",
    "    centers = np.array([normalize_vec(c) for c in centers], dtype=np.float32)\n",
    "    return centers\n",
    "\n",
    "def image_projectors_from_image(img_path, visual_vocab):\n",
    "    \"\"\"\n",
    "    compute SIFT, assign each descriptor to nearest visual word, make projectors for each visual word occurrence\n",
    "    returns list of projectors (dim x dim) where dim = visual_vocab.shape[1]\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return []\n",
    "    kp, d = sift.detectAndCompute(img, None)\n",
    "    if d is None:\n",
    "        return []\n",
    "    # normalize descriptors then match to vocabulary by dot product\n",
    "    d_norm = np.array([normalize_vec(x) for x in d], dtype=np.float32)\n",
    "    # assign using nearest euclidean\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(visual_vocab)\n",
    "    nn_idx = nn.kneighbors(d_norm, return_distance=False).squeeze()\n",
    "    P = []\n",
    "    for idx in nn_idx:\n",
    "        s = visual_vocab[idx]\n",
    "        Pi = np.outer(s, s)\n",
    "        P.append(Pi.astype(np.float32))\n",
    "    return P\n",
    "\n",
    "# -------------------------\n",
    "# Density matrix estimation (QMR)\n",
    "# -------------------------\n",
    "# Implementation notes:\n",
    "# We implement the ascent direction formulas and a backtracking line-search over t in (1, 0.5, 0.25,...)\n",
    "# Stopping when F(rho_new) - F(rho) < eps (paper uses eps=1e-5)\n",
    "# See paper formulas for definitions of F, gradient and Dk. Citations: paper algorithm description. :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "def compute_F_and_grad(rho, projectors, freqs=None):\n",
    "    \"\"\"\n",
    "    rho: torch.tensor (d x d), symmetric PSD trace 1\n",
    "    projectors: list of numpy arrays (d x d)\n",
    "    freqs: optional list of occurrence counts for each projector (defaults 1)\n",
    "    Returns: F (float), grad (torch tensor d x d)\n",
    "    \"\"\"\n",
    "    device = rho.device\n",
    "    d = rho.shape[0]\n",
    "    if freqs is None:\n",
    "        freqs = [1.0] * len(projectors)\n",
    "    F = 0.0\n",
    "    grad = torch.zeros_like(rho)\n",
    "    # small epsilon to avoid log(0)\n",
    "    eps = 1e-12\n",
    "    for Pi_np, f in zip(projectors, freqs):\n",
    "        Pi = torch.from_numpy(Pi_np).to(device)\n",
    "        tr = torch.trace(Pi @ rho).clamp(min=eps)\n",
    "        F += math.log(tr.item()) * f\n",
    "        grad += (f / tr) * Pi\n",
    "    return F, grad\n",
    "\n",
    "def project_to_psd_trace_one(A):\n",
    "    \"\"\"\n",
    "    Ensure symmetric PSD with trace 1 by eigen-decomposition:\n",
    "    A -> U diag(max(eigvals, 0)) U^T / trace\n",
    "    (This is used if numerical stray negativity appears; in iterations we try to keep rho PSD.)\n",
    "    \"\"\"\n",
    "    A_np = A.cpu().numpy()\n",
    "    A_np = (A_np + A_np.T) / 2.0\n",
    "    eigvals, eigvecs = np.linalg.eigh(A_np)\n",
    "    eigvals[eigvals < 0] = 0.0\n",
    "    s = eigvals.sum()\n",
    "    if s <= 0:\n",
    "        # fallback to identity\n",
    "        d = A_np.shape[0]\n",
    "        return torch.from_numpy(np.eye(d, dtype=np.float32)/d)\n",
    "    diag = np.diag(eigvals / s)\n",
    "    rho_np = eigvecs @ diag @ eigvecs.T\n",
    "    return torch.from_numpy(rho_np.astype(np.float32))\n",
    "\n",
    "def estimate_density_matrix(projectors, max_iter=200, eps=1e-5, device='cpu', freqs=None):\n",
    "    \"\"\"\n",
    "    projectors: list of numpy arrays (d x d)\n",
    "    returns rho: torch tensor (d x d) PSD, trace 1\n",
    "    Implements the globally convergent iteration idea from paper (Dbar, Dtilde, Dk).\n",
    "    Reference: paper Algorithm 1 and formulas 4-8. :contentReference[oaicite:5]{index=5}\n",
    "    \"\"\"\n",
    "    d = projectors[0].shape[0]\n",
    "    # initialize rho0 as random diagonal positive with trace 1\n",
    "    diag = np.random.rand(d).astype(np.float32) + 0.1\n",
    "    diag = diag / diag.sum()\n",
    "    rho = torch.from_numpy(np.diag(diag)).to(device)\n",
    "    # main loop\n",
    "    prev_F = None\n",
    "    for k in range(max_iter):\n",
    "        F_val, grad = compute_F_and_grad(rho, projectors, freqs)\n",
    "        # convert grad to torch\n",
    "        # Compute Dbar and Dtilde as in paper\n",
    "        rho_grad = grad.to(device)\n",
    "        # Dbar = grad*rho + rho*grad)/2 - rho\n",
    "        Dbar = (rho_grad @ rho + rho @ rho_grad) * 0.5 - rho\n",
    "        # construct rho_grad @ rho @ rho_grad\n",
    "        temp = rho_grad @ rho @ rho_grad\n",
    "        denom = torch.trace(temp).clamp(min=1e-12)\n",
    "        Dtilde = rho_grad @ rho @ rho_grad / denom - rho\n",
    "        # line search candidates for t: start at 1 then halves\n",
    "        t_candidates = [1.0, 0.5, 0.25, 0.125, 0.0625, 0.03, 0.01, 0.005]\n",
    "        found = False\n",
    "        best_rho = None\n",
    "        best_F = None\n",
    "        for t in t_candidates:\n",
    "            # q(t) = 1 + 2t + t^2 * tr(grad rho grad)\n",
    "            tr_term = torch.trace(rho_grad @ rho @ rho_grad).item()\n",
    "            q = 1.0 + 2.0 * t + (t*t) * tr_term\n",
    "            # Dk = 2/q * Dbar + t*tr(grad rho grad)/q * Dtilde\n",
    "            Dk = (2.0 / q) * Dbar + (t * tr_term / q) * Dtilde\n",
    "            rho_new = rho + t * Dk\n",
    "            # ensure symmetry\n",
    "            rho_new = (rho_new + rho_new.T) / 2.0\n",
    "            # project to PSD & normalize trace if needed\n",
    "            # small fix: if negative eigenvalues exist, project to PSD and renormalize\n",
    "            eigvals = None\n",
    "            try:\n",
    "                eigvals = torch.linalg.eigvalsh(rho_new)\n",
    "            except Exception:\n",
    "                eigvals = torch.from_numpy(np.linalg.eigvalsh(rho_new.cpu().numpy()))\n",
    "            if (eigvals < -1e-8).any():\n",
    "                # projection\n",
    "                rho_new = project_to_psd_trace_one(rho_new).to(device)\n",
    "            else:\n",
    "                # normalize trace to 1\n",
    "                tr = torch.trace(rho_new).item()\n",
    "                if tr <= 0:\n",
    "                    rho_new = project_to_psd_trace_one(rho_new).to(device)\n",
    "                else:\n",
    "                    rho_new = rho_new / tr\n",
    "            # compute F_new\n",
    "            F_new, _ = compute_F_and_grad(rho_new, projectors, freqs)\n",
    "            # require sufficient increase: paper uses Armijo/backtracking to find t that ensures improvement\n",
    "            if prev_F is None or F_new - F_val > 1e-12:\n",
    "                found = True\n",
    "                best_rho = rho_new\n",
    "                best_F = F_new\n",
    "                break\n",
    "        if not found:\n",
    "            # no improvement -> stop\n",
    "            break\n",
    "        # update\n",
    "        if prev_F is not None and abs(best_F - prev_F) < eps:\n",
    "            rho = best_rho\n",
    "            break\n",
    "        rho = best_rho\n",
    "        prev_F = best_F\n",
    "    # final ensure PSD & trace1\n",
    "    rho = (rho + rho.T) / 2.0\n",
    "    rho = project_to_psd_trace_one(rho)\n",
    "    return rho\n",
    "\n",
    "# -------------------------\n",
    "# Simple PyTorch classifier (MLP)\n",
    "# -------------------------\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=512, nclass=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden, hidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden//2, nclass)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_mlp(X_train, y_train, X_val, y_val, input_dim, epochs=30, lr=1e-3, device='cpu'):\n",
    "    model = MLPClassifier(input_dim).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    X_train_t = torch.from_numpy(X_train).float().to(device)\n",
    "    y_train_t = torch.from_numpy(y_train).long().to(device)\n",
    "    X_val_t = torch.from_numpy(X_val).float().to(device)\n",
    "    y_val_t = torch.from_numpy(y_val).long().to(device)\n",
    "    best = None\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        logits = model(X_train_t)\n",
    "        loss = loss_fn(logits, y_train_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = model(X_val_t)\n",
    "            val_preds = val_logits.argmax(dim=1)\n",
    "            acc = (val_preds == y_val_t).float().mean().item()\n",
    "        #print(f\"Epoch {e} loss {loss.item():.4f} val_acc {acc:.4f}\")\n",
    "        best = model\n",
    "    return best\n",
    "\n",
    "# -------------------------\n",
    "# QIMF fusion\n",
    "# -------------------------\n",
    "def qimf_fusion(pt, pi, alpha, beta, cos_theta):\n",
    "    \"\"\"\n",
    "    pt, pi: probabilities for positive class (scalar or numpy arrays)\n",
    "    alpha^2 + beta^2 = 1 expected\n",
    "    returns fused probability for positive\n",
    "    Formula P_u = a^2 P_t + b^2 P_i + 2 a b sqrt(P_t P_i) cosÎ¸\n",
    "    \"\"\"\n",
    "    a2 = alpha*alpha\n",
    "    b2 = beta*beta\n",
    "    term = 2 * alpha * beta * np.sqrt(pt * pi) * cos_theta\n",
    "    pu = a2 * pt + b2 * pi + term\n",
    "    # clip to [0,1]\n",
    "    return np.clip(pu, 0.0, 1.0)\n",
    "\n",
    "# -------------------------\n",
    "# Example pipeline (driver)\n",
    "# -------------------------\n",
    "def example_pipeline(glove_path, image_paths, texts_tokens_list, labels, visual_k=128):\n",
    "    \"\"\"\n",
    "    glove_path: path to glove embeddings\n",
    "    image_paths: list of image file paths aligned with texts_tokens_list and labels\n",
    "    texts_tokens_list: list of token lists\n",
    "    labels: binary 0/1\n",
    "    \"\"\"\n",
    "    emb = load_glove_embeddings(glove_path)\n",
    "    text_dim = len(next(iter(emb.values())))\n",
    "    # build visual vocab\n",
    "    visual_vocab = build_visual_vocab(image_paths, k=visual_k, sample_limit=500)  # sample limit for speed\n",
    "    vis_dim = visual_vocab.shape[1]\n",
    "\n",
    "    # produce projectors for each sample and estimate density matrices\n",
    "    rhos_text = []\n",
    "    rhos_image = []\n",
    "    for tokens, imgp in tqdm(zip(texts_tokens_list, image_paths), total=len(labels), desc=\"Estimating rhos\"):\n",
    "        P_text = word_projectors_from_text(tokens, emb, text_dim)\n",
    "        if len(P_text) == 0:\n",
    "            # fallback to uniform diag\n",
    "            P_text = [np.eye(text_dim, dtype=np.float32)]\n",
    "        rho_t = estimate_density_matrix(P_text, device='cpu')\n",
    "        rhos_text.append(rho_t.cpu().numpy().astype(np.float32))\n",
    "\n",
    "        P_img = image_projectors_from_image(imgp, visual_vocab)\n",
    "        if len(P_img) == 0:\n",
    "            P_img = [np.eye(vis_dim, dtype=np.float32)]\n",
    "        rho_i = estimate_density_matrix(P_img, device='cpu')\n",
    "        rhos_image.append(rho_i.cpu().numpy().astype(np.float32))\n",
    "\n",
    "    # Flatten and prepare datasets\n",
    "    X_text = np.array([r.flatten() for r in rhos_text], dtype=np.float32)\n",
    "    X_img = np.array([r.flatten() for r in rhos_image], dtype=np.float32)\n",
    "    y = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    # split\n",
    "    Xt_tr, Xt_val, yt_tr, yt_val = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "    Xi_tr, Xi_val, yi_tr, yi_val = train_test_split(X_img, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # train MLPs\n",
    "    model_text = train_mlp(Xt_tr, yt_tr, Xt_val, yt_val, input_dim=Xt_tr.shape[1])\n",
    "    model_img = train_mlp(Xi_tr, yi_tr, Xi_val, yi_val, input_dim=Xi_tr.shape[1])\n",
    "\n",
    "    # get probabilities on validation set\n",
    "    device = 'cpu'\n",
    "    with torch.no_grad():\n",
    "        pt_logits = model_text(torch.from_numpy(Xt_val).float().to(device))\n",
    "        pi_logits = model_img(torch.from_numpy(Xi_val).float().to(device))\n",
    "        pt_probs = torch.softmax(pt_logits, dim=1)[:,1].cpu().numpy()\n",
    "        pi_probs = torch.softmax(pi_logits, dim=1)[:,1].cpu().numpy()\n",
    "\n",
    "    # grid search alpha/cos to maximize accuracy on validation\n",
    "    best_acc = -1\n",
    "    best_params = None\n",
    "    alphas = np.linspace(0.1, 0.9, 9)\n",
    "    cos_list = np.linspace(-1.0, 1.0, 21)\n",
    "    for a in alphas:\n",
    "        b = math.sqrt(max(0.0, 1.0 - a*a))\n",
    "        for cos_theta in cos_list:\n",
    "            pu = qimf_fusion(pt_probs, pi_probs, a, b, cos_theta)\n",
    "            preds = (pu >= 0.5).astype(int)\n",
    "            # compute accuracy against yt_val (careful Xt_val/yt_val aligned earlier)\n",
    "            acc = (preds == yt_val).mean()\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_params = (a, b, cos_theta, acc)\n",
    "    print(\"Best fusion params alpha, beta, cos, acc:\", best_params)\n",
    "    return model_text, model_img, best_params\n",
    "\n",
    "# -------------------------\n",
    "# If run as script, show usage example (user must adapt to dataset)\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"This script is a library; adapt example_pipeline() to your dataset paths.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
