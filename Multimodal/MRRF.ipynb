{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973000e-ca46-40bf-b8e7-8854078be48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mr_rf_tensor_fusion.py\n",
    "# PyTorch implementation of a simple MRRF + Tensor Fusion prototype.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "\n",
    "# -------------------------\n",
    "# Helper: projection utils\n",
    "# -------------------------\n",
    "def batch_project_onto(u, v):\n",
    "    \"\"\"\n",
    "    Project vector u onto vector v (batched).\n",
    "    u: (B, D)\n",
    "    v: (B, D)  -- can be the same vector repeated for each batch\n",
    "    returns: projection of u onto v  (B, D)\n",
    "    formula: proj_v(u) = (u·v / v·v) * v\n",
    "    \"\"\"\n",
    "    # add tiny eps for numeric stability\n",
    "    eps = 1e-8\n",
    "    dot = torch.sum(u * v, dim=1, keepdim=True)        # (B,1)\n",
    "    norm2 = torch.sum(v * v, dim=1, keepdim=True) + eps  # (B,1)\n",
    "    coef = dot / norm2                                 # (B,1)\n",
    "    proj = coef * v                                    # (B,D)\n",
    "    return proj\n",
    "\n",
    "# -------------------------\n",
    "# Modality encoders\n",
    "# -------------------------\n",
    "class ModalityEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # (B, hidden_dim)\n",
    "\n",
    "# -------------------------\n",
    "# MRRF + Tensor Fusion Model\n",
    "# -------------------------\n",
    "class MRRF_TensorFusion(nn.Module):\n",
    "    def __init__(self, input_dims, modality_hidden=128, fused_hidden=128, out_dim=2):\n",
    "        \"\"\"\n",
    "        input_dims: list of int, input dimension for each modality (e.g. [300, 50, 128])\n",
    "        modality_hidden: encoded feature dim for each modality after encoder\n",
    "        fused_hidden: hidden dim after fusion\n",
    "        out_dim: number of classes (or 1 for regression)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_modalities = len(input_dims)\n",
    "        self.encoders = nn.ModuleList([\n",
    "            ModalityEncoder(d, modality_hidden) for d in input_dims\n",
    "        ])\n",
    "        # small module to compute a 'shared vector' (redundant component)\n",
    "        # We produce one shared vector per sample by averaging encoders' outputs and passing through a small MLP\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Linear(modality_hidden, modality_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(modality_hidden, modality_hidden)\n",
    "        )\n",
    "        # Optionally compress each residual before tensor fusion\n",
    "        self.residual_projectors = nn.ModuleList([\n",
    "            nn.Linear(modality_hidden, fused_hidden) for _ in input_dims\n",
    "        ])\n",
    "        # final classifier after tensor fusion\n",
    "        # We'll use outer products: (r1 ⊗ r2 ⊗ ...), but full outer grows quickly.\n",
    "        # To keep size manageable, we fuse pairwise and then flatten: (r1 ⊗ r2) concat (r2 ⊗ r3) ...\n",
    "        self.fused_hidden = fused_hidden\n",
    "        pairwise_count = max(1, self.num_modalities - 1)\n",
    "        # classifier on flattened pairwise outer-products\n",
    "        fused_vector_len = pairwise_count * (fused_hidden * fused_hidden)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fused_vector_len, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, *modal_inputs):\n",
    "        \"\"\"\n",
    "        modal_inputs: list of tensors, each (B, input_dim_i)\n",
    "        \"\"\"\n",
    "        B = modal_inputs[0].shape[0]\n",
    "        # 1) encode modalities\n",
    "        encoded = [enc(x) for enc, x in zip(self.encoders, modal_inputs)]  # list of (B, H)\n",
    "        # 2) compute shared/ redundant component estimate\n",
    "        # simple estimate: mean of encodings, then refine with MLP\n",
    "        mean_enc = torch.stack(encoded, dim=0).mean(dim=0)  # (B, H)\n",
    "        shared = self.shared_mlp(mean_enc)                  # (B, H)\n",
    "        # 3) compute residuals by removing projection onto shared direction\n",
    "        residuals = []\n",
    "        for e in encoded:\n",
    "            proj = batch_project_onto(e, shared)  # (B,H)\n",
    "            residual = e - proj\n",
    "            residuals.append(residual)            # (B,H)\n",
    "        # 4) optionally project residuals to smaller fused dim\n",
    "        rp = [proj(res) for proj, res in zip(self.residual_projectors, residuals)]  # list of (B, F)\n",
    "        # 5) tensor fusion using pairwise outer-products (keeps dims manageable)\n",
    "        # Example: for 3 modalities, produce outer(r1,r2), outer(r2,r3)\n",
    "        pairwise = []\n",
    "        for i in range(self.num_modalities - 1):\n",
    "            a = rp[i].unsqueeze(2)  # (B, F, 1)\n",
    "            b = rp[i+1].unsqueeze(1)  # (B, 1, F)\n",
    "            outer = torch.matmul(a, b)  # (B, F, F)\n",
    "            pairwise.append(outer.view(B, -1))  # flatten (B, F*F)\n",
    "        fused_vec = torch.cat(pairwise, dim=1)  # (B, pairwise_count * F * F)\n",
    "        # 6) classification\n",
    "        out = self.classifier(fused_vec)  # (B, out_dim)\n",
    "        return out, {\n",
    "            \"encoded\": encoded,\n",
    "            \"shared\": shared,\n",
    "            \"residuals\": residuals,\n",
    "            \"rp\": rp,\n",
    "            \"fused_vec\": fused_vec\n",
    "        }\n",
    "\n",
    "# -------------------------\n",
    "# Toy training loop (synthetic data)\n",
    "# -------------------------\n",
    "def synthetic_data(num_samples=2000, dims=[300, 50, 128], num_classes=2):\n",
    "    torch.manual_seed(0)\n",
    "    Xs = [torch.randn(num_samples, d) for d in dims]\n",
    "    # create artificial label correlated to sum of first modality's mean and small noise\n",
    "    y = (Xs[0].mean(dim=1) + 0.1 * torch.randn(num_samples) > 0).long()\n",
    "    return Xs, y\n",
    "\n",
    "def train_example():\n",
    "    # config\n",
    "    input_dims = [300, 50, 128]\n",
    "    model = MRRF_TensorFusion(input_dims, modality_hidden=128, fused_hidden=64, out_dim=2)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    Xs, y = synthetic_data(num_samples=2000, dims=input_dims, num_classes=2)\n",
    "    dataset = TensorDataset(Xs[0], Xs[1], Xs[2], y)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(8):\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for xb0, xb1, xb2, lbl in loader:\n",
    "            xb0 = xb0.to(device); xb1 = xb1.to(device); xb2 = xb2.to(device); lbl = lbl.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits, aux = model(xb0, xb1, xb2)\n",
    "            loss = loss_fn(logits, lbl)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * xb0.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == lbl).sum().item()\n",
    "            total += xb0.size(0)\n",
    "        print(f\"Epoch {epoch+1}: loss={total_loss/total:.4f} acc={correct/total:.4f}\")\n",
    "\n",
    "    # example inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample = [Xs[i][:5].to(device) for i in range(len(Xs))]\n",
    "        logits, aux = model(*sample)\n",
    "        print(\"Logits (sample):\", logits)\n",
    "        print(\"Shared vector shape:\", aux[\"shared\"].shape)\n",
    "        print(\"Residual shape (per modality):\", aux[\"residuals\"][0].shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_example()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
